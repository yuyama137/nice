{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mynice.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jxJSVeckPDMC","colab_type":"code","outputId":"93e84a1c-edc2-4c2c-bb9c-8538f77b4539","executionInfo":{"status":"ok","timestamp":1571464659876,"user_tz":-540,"elapsed":1653,"user":{"displayName":"山村悠一朗","photoUrl":"","userId":"06101308947122042258"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GgJ-YmV2PKh6","colab_type":"code","outputId":"dd676411-3629-44d3-a94c-405d3b78ea8f","executionInfo":{"status":"ok","timestamp":1571464661112,"user_tz":-540,"elapsed":2881,"user":{"displayName":"山村悠一朗","photoUrl":"","userId":"06101308947122042258"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["%cd /content/drive/My Drive/nice/mynice/mynice\n","!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/nice/mynice/mynice\n","data\t  image    mynice.ipynb  __pycache__  tyuumoku.md\n","gimon.md  memo.py  nice.py\t train.py     utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ITVRBn6bPeV1","colab_type":"code","colab":{}},"source":["\"\"\"\"\n","NICEの基本設定\n","　- mnistに特化させる\n","　- 最後の層の確率分布は、logistic分布を仮定 \n","\n","\n","\"https://github.com/fmu2/NICE\"を参考に作った\n","\"\"\"\n","\n","import torch, torchvision\n","import numpy as np\n","import torch.utils.data as data\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import nice\n","import utils\n","\n","\n","\n","class args():\n","    batch_size = 200\n","    max_itr = 25000\n","    sample_size = 64# number of size to generate\n","    lr = 1e-3\n","    momentum = 0.9# adamの変数\n","    decay = 0.99#adamのベータの値\n","\n","def main():\n","    # 諸々数値設定\n","    debug = False\n","\n","    device = torch.device(\"cuda:0\")\n","    batch_size = 200\n","    # latent = \"logistic\"\n","    max_itr = 25000\n","    sample_size = 64\n","    coupling = 4\n","    mask_config = 1\n","    num_workers = 8#num_worksは、データを読み込む時に使うスレッドの数\n","\n","    lr = 1e-3\n","    momentum = 0.9\n","    decay = 0.99\n","\n","    # 学習用もテスト用もテンソルに変換するだけ\n","    transform = transforms.Compose([\n","        transforms.ToTensor(), \n","        # transforms.RandomHorizontalFlip()# 0.5の確率で左右反転\n","        ])\n","\n","    trainset = torchvision.datasets.MNIST(root=\"data\", train=True, transform=transform, download=True) #trainset = ((c,h,w),ラベル)\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n","\n","    testset = torchvision.datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=num_workers)# イテレータ\n","\n","#     print(trainloader)\n","\n","    (full_dim, mid_dim, hidden) = (1 * 28 * 28, 1000, 5)\n","\n","    if debug:\n","        # showimg = trainset[0]\n","        print(trainset[0][0].size())\n","        showimg = trainset[0][0].numpy().reshape(28, 28)\n","        plt.imshow(showimg)\n","        plt.show()\n","        # plt.imshow(testset[0])\n","\n","    prior = utils.logistic_distribution()# 事後分布を定義\n","\n","    flow = nice.NICE(prior, in_out_dim=full_dim, mid_dim=mid_dim, \n","                        num_coupling=coupling,hidden=hidden, mask_config=mask_config).to(device)\n","\n","    optimizer = torch.optim.Adam(\n","                    flow.parameters(), lr=lr, betas=(momentum, decay), eps=1e-4)\n","    \n","    total_iter = 0\n","    train = True\n","    running_loss = 0\n","\n","    while train:\n","        for _, data in enumerate(trainloader, 1):\n","            flow.train()  # 学習モード\n","            if total_iter >= max_itr:# 所定の回数学習したら\n","                train = False\n","                break\n","\n","            total_iter += 1\n","            optimizer.zero_grad()# 勾配を初期化\n","\n","#             print(data)\n","\n","            input, _ = data# 上でも書いたが、二つ目の返り値は、ラベル\n","\n","#             print(input)\n","\n","            inputs = utils.prepare_data(input).to(device)# inputはデータローダ。テンソルにする。\n","\n","            outputs, loss = flow(inputs)\n","            loss = -loss.mean()# 出力値(損失関数)のバッチ平均を取っている\n","            running_loss += float(loss)\n","\n","            loss.backward()\n","            optimizer.step()\n","            \n","            if debug:\n","              test_rev = flow(outputs, reverse=True)\n","              print(inputs[0])\n","              print(test_rev[0])\n","\n","            if total_iter % 1000 == 0:# 1000回イテレーションしたら\n","                mean_loss = running_loss / 1000\n","                bit_per_dim = (mean_loss + np.log(256.) * full_dim) \\\n","                            / (full_dim * np.log(2.))\n","                print('iter %s:' % total_iter, \n","                    'loss = %.3f' % mean_loss)\n","                running_loss = 0.0\n","                \n","                # 推論モード。よくわからんけど、学習に最適化された状態から、推論や生成に最適化された状態になる\n","                # 勾配のデータとかがなくなったり、メモリとかが最適化されたりする。\n","                # flow.eval()\n","                device_str = \"cuda:0\"\n","                with torch.no_grad():\n","                    log_dist = utils.logistic_distribution()\n","                    z, _ = flow(inputs)\n","                    testsample = flow(z, reverse=True)\n","                    testsample = utils.prepare_data(testsample, reverse=True)\n","#                     print(testsample)\n","                    torchvision.utils.save_image(torchvision.utils.make_grid(testsample),\n","                        './image/' + \"testmnist\" +'iter%d.png' % total_iter)\n","                    sample = log_dist.sample(size=(10, full_dim), device=\"cuda:0\")\n","                    sample = flow(sample, reverse=True)\n","                    sample = utils.prepare_data(sample, reverse=True)\n","                    torchvision.utils.save_image(torchvision.utils.make_grid(sample),\n","                        './image/' + \"mnist\" +'iter%d.png' % total_iter)\n","                    \n","                    \n","\n","            if debug:\n","                # 推論モード。よくわからんけど、学習に最適化された状態から、推論や生成に最適化された状態になる\n","                # 勾配のデータとかがなくなったり、メモリとかが最適化されたりする。\n","                flow.eval()\n","                with torch.no_grad():\n","                    log_dist = utils.logistic_distribution()\n","                    sample = log_dist.sample((10, full_dim), \"cpu\")\n","                    sample = flow(sample, reverse=True)\n","                    sample *= 255\n","\n","                    print(\"生成完了\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ka-aOzRZP9DK","colab_type":"code","outputId":"1e86fb7f-ef3a-408e-9181-537e16ef1d1a","executionInfo":{"status":"ok","timestamp":1571466045967,"user_tz":-540,"elapsed":1387715,"user":{"displayName":"山村悠一朗","photoUrl":"","userId":"06101308947122042258"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["main()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["iter 1000: loss = 707.019\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 2000: loss = -43.561\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 3000: loss = -684.668\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 4000: loss = -1146.738\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 5000: loss = -1480.323\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 6000: loss = -1729.545\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 7000: loss = -1905.179\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 8000: loss = -1971.315\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 9000: loss = -1993.021\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 10000: loss = -2009.674\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 11000: loss = -2021.560\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 12000: loss = -2030.185\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 13000: loss = -2039.860\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 15000: loss = -2052.563\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 16000: loss = -2060.083\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 17000: loss = -2064.325\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 18000: loss = -2069.204\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 19000: loss = -2074.368\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 20000: loss = -2078.483\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 21000: loss = -2082.638\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 22000: loss = -2087.164\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 23000: loss = -2090.713\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 24000: loss = -2093.459\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n","iter 25000: loss = -2096.730\n","torch.Size([200, 784])\n","torch.Size([200])\n","torch.Size([10, 784])\n","torch.Size([10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OOL8kMkVQDb1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}